{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142fe2a1",
   "metadata": {},
   "source": [
    "# Modulo 7 - Manipolazione dei Dati con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b32913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mysql-connector-python\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  \n",
    "    cnx = mysql.connector.connect(user='root', password='PASSWORD_DI_GABRI',\n",
    "                                  host='127.0.0.1',\n",
    "                                  database='sampledb')\n",
    "    cursor = cnx.cursor()\n",
    "    emps = [(9001, \"Jeff Russell\", \"sales\"), # definire le righe dei dipendenti\n",
    "            (9002, \"Jane Boorman\", \"sales\"),\n",
    "            (9003, \"Tom Heints\", \"sales\")]\n",
    "        \n",
    "    query_add_emp = (\"\"\"INSERT INTO emps (empno, empname, job) VALUES (%s, %s, %s)\"\"\") # definire la query\n",
    "   \n",
    "    for emp in emps:     # inserire le righe dei dipendenti\n",
    "        cursor.execute(query_add_emp, emp)\n",
    "\n",
    "    salary = [(9001, 3000), # definire e inserire gli stipendi\n",
    "                (9002, 2800),\n",
    "                (9003, 2500)]\n",
    "    query_add_salary = (\"\"\"INSERT INTO salary (empno, salary) VALUES (%s, %s)\"\"\")\n",
    "    for sal in salary:\n",
    "        cursor.execute(query_add_salary, sal)\n",
    "    \n",
    "    orders = [(2608, 9001, 35), # definire e inserire gli ordini\n",
    "              (2617, 9001, 35),\n",
    "              (2620, 9001, 139),\n",
    "              (2621, 9002, 95),\n",
    "              (2626, 9002, 218)]\n",
    "\n",
    "    query_add_order = (\"\"\"INSERT INTO orders(pono, empno, total) VALUES (%s, %s, %s)\"\"\")\n",
    "    for order in orders:\n",
    "        cursor.execute(query_add_order, order)\n",
    "\n",
    "    cnx.commit()    # rendere permanenti gli inserimenti nel database\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error-Code:\", err.errno)\n",
    "    print(\"Error-Message: {}\".format(err.msg))\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9002, Jane Boorman, sales\n",
      "9003, Tom Heints, sales\n"
     ]
    }
   ],
   "source": [
    "try:  \n",
    "    cnx = mysql.connector.connect(user='root', password='PASSWORD_DI_GABRI',\n",
    "                                  host='127.0.0.1',\n",
    "                                  database='sampledb')\n",
    "    cursor = cnx.cursor()\n",
    "    query = (\"SELECT * FROM emps WHERE empno > %s\")\n",
    "    empno = 9001\n",
    "    cursor.execute(query, (empno,))\n",
    "    for (empno, empname, job) in cursor:\n",
    "        print(\"{}, {}, {}\".format(empno, empname, job))\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error-Code:\", err.errno)\n",
    "    print(\"Error-Message: {}\".format(err.msg))\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9002, Jane Boorman, sales, 2800\n",
      "9003, Tom Heints, sales, 2500\n"
     ]
    }
   ],
   "source": [
    "# Rispetto a prima aggiunge il salary\n",
    "try:  \n",
    "    cnx = mysql.connector.connect(user='root', password='PASSWORD_DI_GABRI',\n",
    "                                  host='127.0.0.1',\n",
    "                                  database='sampledb')\n",
    "    cursor = cnx.cursor()\n",
    "    query = (\"\"\"SELECT e.empno, e.empname, e.job, s.salary FROM emps e JOIN salary s ON e.empno = s.empno WHERE e.empno > %s\"\"\")\n",
    "    empno = 9001\n",
    "    cursor.execute(query, (empno,))\n",
    "    for (empno, empname, job, salary) in cursor:\n",
    "        print(\"{}, {}, {}, {}\".format(empno, empname, job, salary))\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error-Code:\", err.errno)\n",
    "    print(\"Error-Message: {}\".format(err.msg))\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b14c2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "data = []\n",
    "tickers = ['TSLA', 'ORCL', 'AMZN']\n",
    "for ticker in tickers:\n",
    "    tkr = yf.Ticker(ticker)\n",
    "    hist = tkr.history(period='5d').reset_index()\n",
    "    records = hist[['Date','Close']].to_records(index=False)\n",
    "    records = list(records)\n",
    "    records = [(ticker, str(elem[0])[:10], round(elem[1],2)) for elem in records]\n",
    "    data = data + records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a64224ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TSLA', '2025-05-28', np.float64(356.9))\n",
      "('TSLA', '2025-05-29', np.float64(358.43))\n",
      "('TSLA', '2025-05-30', np.float64(346.46))\n",
      "('TSLA', '2025-06-02', np.float64(342.69))\n",
      "('TSLA', '2025-06-03', np.float64(344.27))\n",
      "('ORCL', '2025-05-28', np.float64(163.85))\n",
      "('ORCL', '2025-05-29', np.float64(162.9))\n",
      "('ORCL', '2025-05-30', np.float64(165.53))\n",
      "('ORCL', '2025-06-02', np.float64(166.57))\n",
      "('ORCL', '2025-06-03', np.float64(169.14))\n",
      "('AMZN', '2025-05-28', np.float64(204.72))\n",
      "('AMZN', '2025-05-29', np.float64(205.7))\n",
      "('AMZN', '2025-05-30', np.float64(205.01))\n",
      "('AMZN', '2025-06-02', np.float64(206.65))\n",
      "('AMZN', '2025-06-03', np.float64(205.71))\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "try:\n",
    "    cnx = mysql.connector.connect(user='root', password='PASSWORD_DI_GABRI',\n",
    "                                  host='127.0.0.1',\n",
    "                                  database='sampledb')\n",
    "    cursor = cnx.cursor()\n",
    "    query_add_stocks = (\"\"\"INSERT INTO stocks (ticker, date, price) VALUES (%s, %s, %s)\"\"\")     # definire la query\n",
    "    cursor.executemany(query_add_stocks, data)     # aggiungere le righe del prezzo delle azioni\n",
    "    # executemany: \n",
    "    cnx.commit()\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error-Code:\", err.errno)\n",
    "    print(\"Error-Message: {}\".format(err.msg))\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cf08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabriele.greco\\AppData\\Local\\Temp\\ipykernel_1772\\149338559.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_stocks = pd.read_sql(query, con=cnx)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "try:\n",
    "    cnx = mysql.connector.connect(user='root', password='PASSWORD_DI_GABRI',\n",
    "                                  host='127.0.0.1',\n",
    "                                  database='sampledb')\n",
    "    query = (\"\"\"SELECT s.* FROM stocks AS s\n",
    "             LEFT JOIN\n",
    "             (SELECT DISTINCT(ticker)\n",
    "                FROM(SELECT price/LAG(price) OVER(PARTITION BY ticker ORDER BY date) AS dif, ticker FROM stocks) AS b\n",
    "                WHERE dif <0.99) AS a ON a.ticker = s.ticker\n",
    "            WHERE a.ticker IS NULL\"\"\")\n",
    "    df_stocks = pd.read_sql(query, con=cnx)\n",
    "    df_stocks = df_stocks.set_index(['ticker','date'])\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error-Code:\", err.errno)\n",
    "    print(\"Error-Message: {}\".format(err.msg))\n",
    "finally:\n",
    "    cnx.close()\n",
    "# ricevo un warning: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy. df_stocks = pd.read_sql(query, con=cnx)\n",
    "# passo un oggetto di connessione mysql.connector.connect(...) direttamente a pd.read_sql().\n",
    "# Pandas supporta ufficialmente solo connessioni SQLAlchemy (o sqlite3),\n",
    "# quindi non garantisce il corretto funzionamento con mysql.connector.    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sqlalchemy mysql-connector-python\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "\n",
    "pw = urllib.parse.quote_plus('PASSWORD_DI_GABRI')\n",
    "\n",
    "engine = create_engine(f\"mysql+mysqlconnector://root:{pw}@127.0.0.1/sampledb\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT s.* FROM stocks AS s\n",
    "LEFT JOIN (\n",
    "    SELECT DISTINCT(ticker)\n",
    "    FROM (\n",
    "        SELECT price / LAG(price) OVER (PARTITION BY ticker ORDER BY date) AS dif, ticker\n",
    "        FROM stocks\n",
    "    ) AS b\n",
    "    WHERE dif < 0.99\n",
    ") AS a ON a.ticker = s.ticker\n",
    "WHERE a.ticker IS NULL\n",
    "\"\"\"\n",
    "\n",
    "df_stocks = pd.read_sql(query, con=engine)\n",
    "df_stocks = df_stocks.set_index(['ticker', 'date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceac656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    price\n",
      "ticker date              \n",
      "ORCL   2025-05-28  163.85\n",
      "       2025-05-29  162.90\n",
      "       2025-05-30  165.53\n",
      "       2025-06-02  166.57\n",
      "       2025-06-03  169.14\n",
      "AMZN   2025-05-28  204.72\n",
      "       2025-05-29  205.70\n",
      "       2025-05-30  205.01\n",
      "       2025-06-02  206.65\n",
      "       2025-06-03  205.71\n"
     ]
    }
   ],
   "source": [
    "print(df_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90346c",
   "metadata": {},
   "source": [
    "## Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "022d750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao dal container!\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "# `docker run --name redis-stack -d -p 6379:6379 redis/redis-stack-server:latest`\n",
    "\n",
    "# Connessione a Redis in esecuzione in Docker sulla porta 6379\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "r.set('messaggio', 'ciao dal container!')\n",
    "print(r.get('messaggio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f782942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Maya Silver'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = redis.Redis()\n",
    "r.mset({\"emp1\": \"Maya Silver\", \"emp2\": \"John Jamison\"})\n",
    "r.get(\"emp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b1c244b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "r.setex(\"cab26\", timedelta(minutes=1), value=\"in the area now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7ab87b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'ID': b'cab48', b'Driver': b'Dan Varsky', b'Brand': b'Volvo'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabDict = {\"ID\": \"cab48\", \"Driver\": \"Dan Varsky\", \"Brand\": \"Volvo\"}\n",
    "r.hset(\"cab48\", mapping=cabDict)\n",
    "r.hgetall(\"cab48\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630ecb4",
   "metadata": {},
   "source": [
    "## Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428c0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('68402146af5003d7b5d25594'), 'nome': 'Mario', 'email': 'mario@example.com'}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connessione a MongoDB (localhost:27017)\n",
    "client = MongoClient(\"mongodb://admin:secret@localhost:27017/\")\n",
    "db = client[\"miodatabase\"] # Accedi a un database (verrà creato se non esiste)\n",
    "collezione = db[\"utenti\"] # Accedi a una collezione\n",
    "collezione.insert_one({\"nome\": \"Mario\", \"email\": \"mario@example.com\"}) # Inserisci un documento\n",
    "for utente in collezione.find(): # Recupera e stampa tutti i documenti\n",
    "    print(utente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e16aed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://admin:secret@localhost:27017/\")\n",
    "\n",
    "db = client['sampledb'] # per accedere agli attributi: db = client.sampledb\n",
    "emps_collection = db['emps']\n",
    "\n",
    "emp = {\"empno\": 9001, \"empname\": \"Jeff Russell\", \"orders\": [2608, 2617, 2620]}\n",
    "result = emps_collection.insert_one(emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "935cea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68402237af5003d7b5d2559d\n"
     ]
    }
   ],
   "source": [
    "print(result.inserted_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = emps_collection.find_one({\"empno\": 9001})\n",
    "print(emp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eac048",
   "metadata": {},
   "source": [
    "# Aggregazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7492fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    orders = [(9423517, '2022-02-04', 9001),\n",
    "              (4626232, '2022-02-04', 9003),\n",
    "              (9423534, '2022-02-04', 9001),\n",
    "              (9423679, '2022-02-05', 9002),\n",
    "              (4626377, '2022-02-05', 9003),\n",
    "              (4626412, '2022-02-05', 9004),\n",
    "              (9423783, '2022-02-06', 9002),\n",
    "              (4626490, '2022-02-06', 9004)]\n",
    "    \n",
    "    details = [(9423517, 'Jeans', 'Rip Curl', 87.0, 1),\n",
    "               (9423517, 'Jacket', 'The North Face', 112.0, 1),\n",
    "               (4626232, 'Socks', 'Vans', 15.0, 1),\n",
    "               (4626232, 'Jeans', 'Quiksilver', 82.0, 1),\n",
    "               (9423534, 'Socks', 'DC', 10.0, 2),\n",
    "               (9423534, 'Socks', 'Quiksilver', 12.0, 2),\n",
    "               (9423679, 'T-shirt', 'Patagonia', 35.0, 1),\n",
    "               (4626377, 'Hoody', 'Animal', 44.0, 1),\n",
    "               (4626377, 'Cargo Shorts', 'Animal', 38.0, 1),\n",
    "               (4626412, 'Shirt', 'Volcom', 78.0, 1),\n",
    "               (9423783, 'Boxer Shorts', 'Superdry', 30.0, 2),\n",
    "               (9423783, 'Shorts', 'Globe', 26.0, 1),\n",
    "               (4626490, 'Cargo Shorts', 'Billabong', 54.0, 1),\n",
    "               (4626490, 'Sweater', 'Dickies', 56.0, 1)]\n",
    "\n",
    "    df_details = pd.DataFrame(details, columns =['OrderNo', 'Item', 'Brand', 'Price', 'Quantity'])\n",
    "    df_orders = pd.DataFrame(orders, columns =['OrderNo', 'Date', 'Empno'])\n",
    "    \n",
    "    emps = [(9001, 'Jeff Russell', 'LA'),\n",
    "            (9002, 'Jane Boorman', 'San Francisco'),\n",
    "            (9003, 'Tom Heints', 'NYC'),\n",
    "            (9004, 'Maya Silver', 'Philadelphia')]\n",
    "    df_emps = pd.DataFrame(emps, columns =['Empno', 'Empname', 'Location'])\n",
    "    \n",
    "    locations = [('LA', 'West'),\n",
    "                 ('San Francisco', 'West'),\n",
    "                 ('NYC', 'East'),\n",
    "                 ('Philadelphia', 'East')]\n",
    "    df_locations = pd.DataFrame(locations, columns =['Location', 'Region'])\n",
    "    return df_orders, df_details, df_emps, df_locations\n",
    "\n",
    "def combination(df_orders, df_details, df_emps, df_locations):\n",
    "    df_sales = df_orders.merge(df_details)\n",
    "    return df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeffd40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati caricati\n",
      "\n",
      "    OrderNo        Date  Empno          Item           Brand  Price  Quantity\n",
      "0   9423517  2022-02-04   9001         Jeans        Rip Curl   87.0         1\n",
      "1   9423517  2022-02-04   9001        Jacket  The North Face  112.0         1\n",
      "2   4626232  2022-02-04   9003         Socks            Vans   15.0         1\n",
      "3   4626232  2022-02-04   9003         Jeans      Quiksilver   82.0         1\n",
      "4   9423534  2022-02-04   9001         Socks              DC   10.0         2\n",
      "5   9423534  2022-02-04   9001         Socks      Quiksilver   12.0         2\n",
      "6   9423679  2022-02-05   9002       T-shirt       Patagonia   35.0         1\n",
      "7   4626377  2022-02-05   9003         Hoody          Animal   44.0         1\n",
      "8   4626377  2022-02-05   9003  Cargo Shorts          Animal   38.0         1\n",
      "9   4626412  2022-02-05   9004         Shirt          Volcom   78.0         1\n",
      "10  9423783  2022-02-06   9002  Boxer Shorts        Superdry   30.0         2\n",
      "11  9423783  2022-02-06   9002        Shorts           Globe   26.0         1\n",
      "12  4626490  2022-02-06   9004  Cargo Shorts       Billabong   54.0         1\n",
      "13  4626490  2022-02-06   9004       Sweater         Dickies   56.0         1\n"
     ]
    }
   ],
   "source": [
    "df_orders, df_details, df_emps, df_locations = load_data()\n",
    "print(\"Dati caricati\\n\")\n",
    "df_sales = combination(df_orders, df_details, df_emps, df_locations)\n",
    "print(df_sales)\n",
    "df_sales['Total'] = df_sales['Price'] * df_sales['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86328e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Empno  Total       Empname       Location Region\n",
      "0   2022-02-04   9001   87.0  Jeff Russell             LA   West\n",
      "1   2022-02-04   9001  112.0  Jeff Russell             LA   West\n",
      "2   2022-02-04   9003   15.0    Tom Heints            NYC   East\n",
      "3   2022-02-04   9003   82.0    Tom Heints            NYC   East\n",
      "4   2022-02-04   9001   20.0  Jeff Russell             LA   West\n",
      "5   2022-02-04   9001   24.0  Jeff Russell             LA   West\n",
      "6   2022-02-05   9002   35.0  Jane Boorman  San Francisco   West\n",
      "7   2022-02-05   9003   44.0    Tom Heints            NYC   East\n",
      "8   2022-02-05   9003   38.0    Tom Heints            NYC   East\n",
      "9   2022-02-05   9004   78.0   Maya Silver   Philadelphia   East\n",
      "10  2022-02-06   9002   60.0  Jane Boorman  San Francisco   West\n",
      "11  2022-02-06   9002   26.0  Jane Boorman  San Francisco   West\n",
      "12  2022-02-06   9004   54.0   Maya Silver   Philadelphia   East\n",
      "13  2022-02-06   9004   56.0   Maya Silver   Philadelphia   East\n",
      "          Date Region  Total\n",
      "0   2022-02-04   West   87.0\n",
      "1   2022-02-04   West  112.0\n",
      "2   2022-02-04   East   15.0\n",
      "3   2022-02-04   East   82.0\n",
      "4   2022-02-04   West   20.0\n",
      "5   2022-02-04   West   24.0\n",
      "6   2022-02-05   West   35.0\n",
      "7   2022-02-05   East   44.0\n",
      "8   2022-02-05   East   38.0\n",
      "9   2022-02-05   East   78.0\n",
      "10  2022-02-06   West   60.0\n",
      "11  2022-02-06   West   26.0\n",
      "12  2022-02-06   East   54.0\n",
      "13  2022-02-06   East   56.0\n",
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-04 East     97.0\n",
      "           West    243.0\n",
      "2022-02-05 East    160.0\n",
      "           West     35.0\n",
      "2022-02-06 East    110.0\n",
      "           West     86.0\n"
     ]
    }
   ],
   "source": [
    "# Per filtrare il DataFrame fino alle colonne necessarie, occorre passare una lista dei nomi delle colonne all’operatore [] del DataFrame, come mostrato qui:\n",
    "df_sales = df_sales[['Date','Empno','Total']]\n",
    "\n",
    "df_sales_emps = df_sales.merge(df_emps)\n",
    "df_result = df_sales_emps.merge(df_locations)\n",
    "print(df_result)\n",
    "\n",
    "df_result = df_result[['Date','Region','Total']]\n",
    "print(df_result)\n",
    "\n",
    "df_date_region = df_result.groupby(['Date','Region']).sum()\n",
    "print(df_date_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c0011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('2022-02-04', 'East'),\n",
      "            ('2022-02-04', 'West'),\n",
      "            ('2022-02-05', 'East'),\n",
      "            ('2022-02-05', 'West'),\n",
      "            ('2022-02-06', 'East'),\n",
      "            ('2022-02-06', 'West')],\n",
      "           names=['Date', 'Region'])\n",
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-05 West     35.0\n",
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-05 East    160.0\n",
      "           West     35.0\n",
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-04 East     97.0\n",
      "2022-02-05 West     35.0\n",
      "2022-02-06 East    110.0\n"
     ]
    }
   ],
   "source": [
    "print(df_date_region.index) # per vedere come lavora il multiindex\n",
    "\n",
    "print(df_date_region[df_date_region.index.isin( [('2022-02-05', 'West')])])\n",
    "print(df_date_region[df_date_region.index.isin([('2022-02-05', 'East'), ('2022-02-05', 'West')])])\n",
    "print(df_date_region[df_date_region.index.isin([('2022-02-06', 'East'),('2022-02-04', 'East'), ('2022-02-05', 'West')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db10401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-04 East     97.0\n",
      "           West    243.0\n",
      "2022-02-05 East    160.0\n",
      "           West     35.0\n",
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-04 East     97.0\n",
      "           West    243.0\n",
      "2022-02-05 East    160.0\n",
      "           West     35.0\n",
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-05 East    160.0\n",
      "           West     35.0\n",
      "2022-02-06 East    110.0\n",
      "           West     86.0\n"
     ]
    }
   ],
   "source": [
    "# SLICING di aggregation\n",
    "print(df_date_region[('2022-02-04', 'East'):('2022-02-05', 'West')])\n",
    "\n",
    "print(df_date_region['2022-02-04':'2022-02-05'])\n",
    "# qui si utilizza lo slice due volte\n",
    "print(df_date_region.loc[(slice('2022-02-05', '2022-02-06'), slice(None)), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc0e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-05</th>\n",
       "      <th>East</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-06</th>\n",
       "      <th>East</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Total\n",
       "Date       Region       \n",
       "2022-02-05 East    160.0\n",
       "2022-02-06 East    110.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date_region.loc[(slice('2022-02-05', '2022-02-06'), slice('East')), :]\n",
    "# possiamo specificare anche un intervallo region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1b0524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    731.0\n",
      "dtype: float64\n",
      "                 Total\n",
      "2022-02-04 East   97.0\n",
      "           West  243.0\n",
      "2022-02-05 East  160.0\n",
      "           West   35.0\n",
      "2022-02-06 East  110.0\n",
      "           West   86.0\n",
      "All        All   731.0\n",
      "         Total\n",
      "All All  731.0\n"
     ]
    }
   ],
   "source": [
    "# Aggiungere un totale generale\n",
    "ps = df_date_region.sum(axis = 0)\n",
    "print(ps) # sum restituisce una series pandas con la somma sulal colonna total\n",
    "ps.name=('All','All')\n",
    "        # il primo all si riferisce alla componente date delal chiave mentre il secondo alla Region\n",
    "# df_date_region_total = df_date_region.append(ps)\n",
    "df_date_region_total = pd.concat([df_date_region, ps.to_frame().T])\n",
    "print(df_date_region_total)\n",
    "print(df_date_region_total[df_date_region_total.index.isin([('All', 'All')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total\n",
      "2022-02-04 East   97.0\n",
      "           West  243.0\n",
      "           All   340.0\n",
      "2022-02-05 East  160.0\n",
      "           West   35.0\n",
      "           All   195.0\n",
      "2022-02-06 East  110.0\n",
      "           West   86.0\n",
      "           All   196.0\n"
     ]
    }
   ],
   "source": [
    "# aggiungere totali parziali\n",
    "df_totals = []\n",
    "\n",
    "for date, date_df in df_date_region.groupby(level=0):\n",
    "    df_totals.append(date_df)  # aggiunge le righe esistenti\n",
    "    ps = date_df.sum(axis=0)\n",
    "    ps.name = (date, 'All')  # MultiIndex (data, 'All')\n",
    "    df_totals.append(ps.to_frame().T)  # aggiunge la riga di somma\n",
    "\n",
    "# Unisce tutto in un unico DataFrame\n",
    "df_totals = pd.concat(df_totals)\n",
    "print(df_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583f3c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2022-02-04</th>\n",
       "      <th>East</th>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2022-02-05</th>\n",
       "      <th>East</th>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2022-02-06</th>\n",
       "      <th>East</th>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">All</th>\n",
       "      <th>All</th>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>731.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total\n",
       "2022-02-04 East   97.0\n",
       "           West  243.0\n",
       "           All   340.0\n",
       "2022-02-05 East  160.0\n",
       "           West   35.0\n",
       "           All   195.0\n",
       "2022-02-06 East  110.0\n",
       "           West   86.0\n",
       "           All   196.0\n",
       "All        All   731.0\n",
       "           All   731.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_totals = pd.concat([df_totals, df_date_region_total.loc[[('All', 'All')]]])\n",
    "df_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d3b391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>West</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>West</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>West</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>West</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Region  Total\n",
       "0  2022-02-04   West   87.0\n",
       "1  2022-02-04   West  112.0\n",
       "4  2022-02-04   West   20.0\n",
       "5  2022-02-04   West   24.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RIGHE APPARTENENTI AD UN GRUPPO\n",
    "group = df_result.groupby(['Date','Region'])\n",
    "group.get_group(('2022-02-04','West'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acddaa3",
   "metadata": {},
   "source": [
    "## Combinare i dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f1208b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9423517, '2022-02-04', 9001), (4626232, '2022-02-04', 9002), (9423534, '2022-02-04', 9001), (9423679, '2022-02-05', 9002), (4626377, '2022-02-05', 9003), (4626412, '2022-02-05', 9004), (9423783, '2022-02-06', 9002), (4626490, '2022-02-06', 9004)]\n"
     ]
    }
   ],
   "source": [
    "orders_2022_02_04 = [\n",
    "    (9423517, '2022-02-04', 9001),\n",
    "    (4626232, '2022-02-04', 9002),\n",
    "    (9423534, '2022-02-04', 9001)]\n",
    "orders_2022_02_05 = [\n",
    "    (9423679, '2022-02-05', 9002),\n",
    "    (4626377, '2022-02-05', 9003),\n",
    "    (4626412, '2022-02-05', 9004)]\n",
    "orders_2022_02_06 = [\n",
    "    (9423783, '2022-02-06', 9002),\n",
    "    (4626490, '2022-02-06', 9004)]\n",
    "orders = orders_2022_02_04 + orders_2022_02_05 + orders_2022_02_06\n",
    "print(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "842705ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OrderNo': 9423517, 'Date': '2022-02-04', 'Empno': 9001, 'ShippingInstructions': {'name': 'John Silver', 'Phone': [{'type': 'Office', 'number': '809-123-9309'}, {'type': 'Mobile', 'number': '417-123-4567'}]}}\n"
     ]
    }
   ],
   "source": [
    "# l'operatore ** scompone un dizionario nelle sue singole coppie chiave valore\n",
    "extra_fields_9423517 = {'ShippingInstructions' :\n",
    "    { 'name' : 'John Silver',\n",
    "     'Phone' : [{ 'type' : 'Office', 'number' : '809-123-9309' },\n",
    "                { 'type' : 'Mobile', 'number' : '417-123-4567' }\n",
    "                ]}\n",
    "    }\n",
    "order_9423517 = {'OrderNo':9423517, 'Date':'2022-02-04', 'Empno':9001}\n",
    "order_9423517 = {**order_9423517, **extra_fields_9423517}\n",
    "print(order_9423517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bdd52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9423517, '2022-02-04', 9001, 'Jeans', 'Rip Curl', 87.0, 1)\n",
      "(9423517, '2022-02-04', 9001, 'Jacket', 'The North Face', 112.0, 1)\n",
      "(4626232, '2022-02-04', 9002, 'Socks', 'Vans', 15.0, 1)\n",
      "(4626232, '2022-02-04', 9002, 'Jans', 'Quicksilver', 82.0, 1)\n",
      "(9423534, '2022-02-04', 9001, 'Socks', 'DC', 10.0, 2)\n",
      "(9423534, '2022-02-04', 9001, 'Socks', 'Quicksilver', 12.0, 2)\n",
      "(9423679, '2022-02-05', 9002, 'T-shirt', 'Patagonia', 35.0, 1)\n",
      "(4626377, '2022-02-05', 9003, 'Hoody', 'Animal', 44.0, 1)\n",
      "(4626377, '2022-02-05', 9003, 'Cargo Shorts', 'Animal', 38.0, 1)\n",
      "(4626412, '2022-02-05', 9004, 'Shirt', 'Volcom', 78.0, 1)\n",
      "(9423783, '2022-02-06', 9002, 'Boxer Shorts', 'Superdry', 30.0, 2)\n",
      "(9423783, '2022-02-06', 9002, 'Shorts', 'Globe', 26.0, 1)\n",
      "(4626490, '2022-02-06', 9004, 'Cargo Shorts', 'Billabong', 54.0, 1)\n",
      "(4626490, '2022-02-06', 9004, 'Sweater', 'Dickies', 56.0, 1)\n",
      "[(9423517, '2022-02-04', 9001, 'Jeans', 'Rip Curl', 87.0, 1), (9423517, '2022-02-04', 9001, 'Jacket', 'The North Face', 112.0, 1), (4626232, '2022-02-04', 9002, 'Socks', 'Vans', 15.0, 1), (4626232, '2022-02-04', 9002, 'Jans', 'Quicksilver', 82.0, 1), (9423534, '2022-02-04', 9001, 'Socks', 'DC', 10.0, 2), (9423534, '2022-02-04', 9001, 'Socks', 'Quicksilver', 12.0, 2), (9423679, '2022-02-05', 9002, 'T-shirt', 'Patagonia', 35.0, 1), (4626377, '2022-02-05', 9003, 'Hoody', 'Animal', 44.0, 1), (4626377, '2022-02-05', 9003, 'Cargo Shorts', 'Animal', 38.0, 1), (4626412, '2022-02-05', 9004, 'Shirt', 'Volcom', 78.0, 1), (9423783, '2022-02-06', 9002, 'Boxer Shorts', 'Superdry', 30.0, 2), (9423783, '2022-02-06', 9002, 'Shorts', 'Globe', 26.0, 1), (4626490, '2022-02-06', 9004, 'Cargo Shorts', 'Billabong', 54.0, 1), (4626490, '2022-02-06', 9004, 'Sweater', 'Dickies', 56.0, 1)]\n"
     ]
    }
   ],
   "source": [
    "details = [\n",
    "    (9423517, 'Jeans', 'Rip Curl', 87.0, 1),\n",
    "    (9423517, 'Jacket', 'The North Face', 112.0, 1),\n",
    "    (4626232, 'Socks', 'Vans', 15.0, 1),\n",
    "    (4626232, 'Jans', 'Quicksilver', 82.0, 1),\n",
    "    (9423534, 'Socks', 'DC', 10.0, 2),\n",
    "    (9423534, 'Socks', 'Quicksilver', 12.0, 2),\n",
    "    (9423679, 'T-shirt', 'Patagonia', 35.0, 1),\n",
    "    (4626377, 'Hoody', 'Animal', 44.0, 1),\n",
    "    (4626377, 'Cargo Shorts', 'Animal', 38.0, 1),\n",
    "    (4626412, 'Shirt', 'Volcom', 78.0, 1),\n",
    "    (9423783, 'Boxer Shorts', 'Superdry', 30.0, 2),\n",
    "    (9423783, 'Shorts', 'Globe', 26.0, 1),\n",
    "    (4626490, 'Cargo Shorts', 'Billabong', 54.0, 1),\n",
    "    (4626490, 'Sweater', 'Dickies', 56.0, 1),\n",
    "]\n",
    "orders_details = []\n",
    "for o in orders:\n",
    "    for d in details:\n",
    "        if d[0] == o[0]:\n",
    "            orders_details.append(o + d[1:]) # slicing per la tupla details\n",
    "# più pythonica\n",
    "orders_details = []\n",
    "orders_details = [[o for o in orders if d[0] == o[0]][0] + d[1:] for d in details]\n",
    "for o in orders_details:\n",
    "    print(o)\n",
    "print(orders_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43aab948",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# diversi tipi di join per le liste\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# la lista details potrebbe contenere righe d’ordine per ordini non presenti nella lista orders.\u001b[39;00m\n\u001b[32m      3\u001b[39m details.append((\u001b[32m4626592\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mShorts\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mProtest\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m48.0\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m orders_details = [\u001b[43m[\u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m + d[\u001b[32m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m details]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# diversi tipi di join per le liste\n",
    "# la lista details potrebbe contenere righe d’ordine per ordini non presenti nella lista orders.\n",
    "details.append((4626592, 'Shorts', 'Protest', 48.0, 1))\n",
    "orders_details = [[o for o in orders if d[0] == o][0] + d[1:] for d in details]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed798424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9423517, '2022-02-04', 9001, 'Jeans', 'Rip Curl', 87.0, 1)\n",
      "(9423517, '2022-02-04', 9001, 'Jacket', 'The North Face', 112.0, 1)\n",
      "(4626232, '2022-02-04', 9002, 'Socks', 'Vans', 15.0, 1)\n",
      "(4626232, '2022-02-04', 9002, 'Jans', 'Quicksilver', 82.0, 1)\n",
      "(9423534, '2022-02-04', 9001, 'Socks', 'DC', 10.0, 2)\n",
      "(9423534, '2022-02-04', 9001, 'Socks', 'Quicksilver', 12.0, 2)\n",
      "(9423679, '2022-02-05', 9002, 'T-shirt', 'Patagonia', 35.0, 1)\n",
      "(4626377, '2022-02-05', 9003, 'Hoody', 'Animal', 44.0, 1)\n",
      "(4626377, '2022-02-05', 9003, 'Cargo Shorts', 'Animal', 38.0, 1)\n",
      "(4626412, '2022-02-05', 9004, 'Shirt', 'Volcom', 78.0, 1)\n",
      "(9423783, '2022-02-06', 9002, 'Boxer Shorts', 'Superdry', 30.0, 2)\n",
      "(9423783, '2022-02-06', 9002, 'Shorts', 'Globe', 26.0, 1)\n",
      "(4626490, '2022-02-06', 9004, 'Cargo Shorts', 'Billabong', 54.0, 1)\n",
      "(4626490, '2022-02-06', 9004, 'Sweater', 'Dickies', 56.0, 1)\n",
      "(4626592, None, None, 'Shorts', 'Protest', 48.0, 1)\n"
     ]
    }
   ],
   "source": [
    "orders_details = [[o for o in orders if d[0] in o][0] + d[1:] for d in details if d[0] in [o[0] for o in orders]]\n",
    "# Il problema viene eliminato escludendo tutte le righe details che non hanno una riga\n",
    "# corrispondente nella lista orders e implementando il controllo nella clausola if che\n",
    "# segue il ciclo for d in details.\n",
    "\n",
    "# per fare un right join\n",
    "# una right join restituisce tutte le righe del dataset destro e solo le righe corrispondenti del dataset sinistro\n",
    "orders_details_right = [[o for o in orders if d[0] in o][0] + d[1:] if d[0] in [o[0] for o in orders] else (d[0], None, None) + d[1:] for d in details]\n",
    "for o in orders_details_right:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f12344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779.0\n",
      "731.0\n"
     ]
    }
   ],
   "source": [
    "s = sum(pr*qt for _, _, _, _, _, pr, qt in orders_details_right)\n",
    "print(s)\n",
    "s = sum(pr*qt for _, dt, _, _, _, pr, qt in orders_details_right if dt != None)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582469f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2700 3000 3000]\n",
      " [2600 2800 2800]\n",
      " [2300 2500 2500]\n",
      " [2200 2400 2400]\n",
      " [2500 2700 2700]]\n"
     ]
    }
   ],
   "source": [
    "# CONCATENARE ARRAY NUMPY\n",
    "import numpy as np\n",
    "jeff_salary = [2700, 3000, 3000]\n",
    "nick_salary = [2600, 2800, 2800]\n",
    "tom_salary = [2300, 2500, 2500]\n",
    "base_salary1 = np.array([jeff_salary, nick_salary, tom_salary])\n",
    "\n",
    "maya_salary = [2200, 2400, 2400]\n",
    "john_salary = [2500, 2700, 2700]\n",
    "base_salary2 = np.array([maya_salary, john_salary])\n",
    "\n",
    "base_salary = np.concatenate((base_salary1, base_salary2), axis=0)\n",
    "print(base_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ddb5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2700 3000 3000 3000]\n",
      " [2600 2800 2800 2900]\n",
      " [2300 2500 2500 2500]\n",
      " [2200 2400 2400 2500]\n",
      " [2500 2700 2700 2700]]\n"
     ]
    }
   ],
   "source": [
    "new_month_salary = np.array([[3000],[2900],[2500],[2500],[2700]])\n",
    "base_salary = np.concatenate((base_salary, new_month_salary), axis=1)\n",
    "print(base_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61b64471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        jeff  nick   tom\n",
      "June    2700  2600  2300\n",
      "July    3000  2800  2500\n",
      "August  3000  2800  2500\n",
      "      June  July  August\n",
      "jeff  2700  3000    3000\n",
      "nick  2600  2800    2800\n",
      "tom   2300  2500    2500\n"
     ]
    }
   ],
   "source": [
    "# Concatenere dataframe\n",
    "import pandas as pd\n",
    "salary_df1 = pd.DataFrame({\n",
    "    'jeff': jeff_salary,\n",
    "    'nick': nick_salary,\n",
    "    'tom': tom_salary\n",
    "})\n",
    "salary_df1.index = ['June', 'July', 'August']\n",
    "print(salary_df1)\n",
    "salary_df1 = salary_df1.T # Traspose\n",
    "print(salary_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25827eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df2 = pd.DataFrame({\n",
    "    'maya': maya_salary,\n",
    "    'john': john_salary},\n",
    "    index = ['June', 'July', 'August']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4881beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      June  July  August\n",
      "jeff  2700  3000    3000\n",
      "nick  2600  2800    2800\n",
      "tom   2300  2500    2500\n",
      "maya  2200  2400    2400\n",
      "john  2500  2700    2700\n"
     ]
    }
   ],
   "source": [
    "salary_df = pd.concat([salary_df1, salary_df2])\n",
    "print(salary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73a1f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df3 = pd.DataFrame({\n",
    "    'September': [3000,2800,2500,2400,2700],\n",
    "    'October': [3200,3000,2700,2500,2900]},\n",
    "    index = ['jeff', 'nick', 'tom', 'maya', 'john'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa587718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      June  July  August  September  October\n",
      "jeff  2700  3000    3000       3000     3200\n",
      "nick  2600  2800    2800       2800     3000\n",
      "tom   2300  2500    2500       2500     2700\n",
      "maya  2200  2400    2400       2400     2500\n",
      "john  2500  2700    2700       2700     2900\n"
     ]
    }
   ],
   "source": [
    "salary_df = pd.concat([salary_df, salary_df3], axis=1)\n",
    "print(salary_df)  # con axis 1 facciamo il concat orizzontale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee892612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      June  July  August\n",
      "jeff  2700  3000    3000\n",
      "nick  2600  2800    2800\n",
      "tom   2300  2500    2500\n",
      "maya  2200  2400    2400\n",
      "john  2500  2700    2700\n"
     ]
    }
   ],
   "source": [
    "salary_df = salary_df.drop(['September', 'October'], axis=1)\n",
    "print(salary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b2a8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      June  July  August\n",
      "jeff  2700  3000    3000\n",
      "tom   2300  2500    2500\n",
      "john  2500  2700    2700\n"
     ]
    }
   ],
   "source": [
    "salary_df = salary_df.drop(['nick', 'maya'], axis=0)\n",
    "print(salary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c9bd6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Total\n",
      "Date       Region       \n",
      "2022-02-04 East     97.0\n",
      "           South   114.0\n",
      "           West    243.0\n",
      "2022-02-05 East    160.0\n",
      "           South   325.0\n",
      "           West     35.0\n",
      "2022-02-06 East    110.0\n",
      "           South   212.0\n",
      "           West     86.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenere dataframe multiindex\n",
    "df_date_region1 = pd.DataFrame([\n",
    "    ('2022-02-04', 'East', 97.0),\n",
    "    ('2022-02-04', 'West', 243.0),\n",
    "    ('2022-02-05', 'East', 160.0),\n",
    "    ('2022-02-05', 'West', 35.0),\n",
    "    ('2022-02-06', 'East', 110.0),\n",
    "    ('2022-02-06', 'West', 86.0)],\n",
    "    columns = ['Date', 'Region', 'Total']).set_index(['Date', 'Region'])\n",
    "\n",
    "df_date_region2 = pd.DataFrame([\n",
    "    ('2022-02-04', 'South', 114.0),\n",
    "    ('2022-02-05', 'South', 325.0),\n",
    "    ('2022-02-06', 'South', 212.0)],\n",
    "    columns=['Date', 'Region', 'Total']).set_index(['Date', 'Region'])\n",
    "\n",
    "df_date_region = pd.concat([df_date_region1, df_date_region2]).sort_index(level=['Date','Region'])\n",
    "print(df_date_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e3b1569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OrderNo        Date   Empno          Item           Brand  Price  Quantity\n",
      "0   9423517  2022-02-04  9001.0         Jeans        Rip Curl   87.0         1\n",
      "1   9423517  2022-02-04  9001.0        Jacket  The North Face  112.0         1\n",
      "2   4626232  2022-02-04  9002.0         Socks            Vans   15.0         1\n",
      "3   4626232  2022-02-04  9002.0          Jans     Quicksilver   82.0         1\n",
      "4   9423534  2022-02-04  9001.0         Socks              DC   10.0         2\n",
      "5   9423534  2022-02-04  9001.0         Socks     Quicksilver   12.0         2\n",
      "6   9423679  2022-02-05  9002.0       T-shirt       Patagonia   35.0         1\n",
      "7   4626377  2022-02-05  9003.0         Hoody          Animal   44.0         1\n",
      "8   4626377  2022-02-05  9003.0  Cargo Shorts          Animal   38.0         1\n",
      "9   4626412  2022-02-05  9004.0         Shirt          Volcom   78.0         1\n",
      "10  9423783  2022-02-06  9002.0  Boxer Shorts        Superdry   30.0         2\n",
      "11  9423783  2022-02-06  9002.0        Shorts           Globe   26.0         1\n",
      "12  4626490  2022-02-06  9004.0  Cargo Shorts       Billabong   54.0         1\n",
      "13  4626490  2022-02-06  9004.0       Sweater         Dickies   56.0         1\n",
      "14  4626592         NaN     NaN        Shorts         Protest   48.0         1\n",
      "15  4626592         NaN     NaN        Shorts         Protest   48.0         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_orders = pd.DataFrame(orders, columns =['OrderNo', 'Date', 'Empno'])\n",
    "df_details = pd.DataFrame(details, columns =['OrderNo', 'Item', 'Brand','Price', 'Quantity'])\n",
    "\n",
    "new_row = pd.DataFrame([{\n",
    "    'OrderNo': 4626592,\n",
    "    'Item': 'Shorts',\n",
    "    'Brand': 'Protest',\n",
    "    'Price': 48.0,\n",
    "    'Quantity': 1\n",
    "}])\n",
    "\n",
    "df_details = pd.concat([df_details, new_row], ignore_index=True)\n",
    "df_orders_details_right = df_orders.merge(df_details, how='right',left_on='OrderNo', right_on='OrderNo')\n",
    "print(df_orders_details_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38ed7348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderNo       int64\n",
      "Date         object\n",
      "Empno       float64\n",
      "Item         object\n",
      "Brand        object\n",
      "Price       float64\n",
      "Quantity      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_orders_details_right.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a519b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OrderNo        Date  Empno          Item           Brand  Price  Quantity\n",
      "0   9423517  2022-02-04   9001         Jeans        Rip Curl   87.0         1\n",
      "1   9423517  2022-02-04   9001        Jacket  The North Face  112.0         1\n",
      "2   4626232  2022-02-04   9002         Socks            Vans   15.0         1\n",
      "3   4626232  2022-02-04   9002          Jans     Quicksilver   82.0         1\n",
      "4   9423534  2022-02-04   9001         Socks              DC   10.0         2\n",
      "5   9423534  2022-02-04   9001         Socks     Quicksilver   12.0         2\n",
      "6   9423679  2022-02-05   9002       T-shirt       Patagonia   35.0         1\n",
      "7   4626377  2022-02-05   9003         Hoody          Animal   44.0         1\n",
      "8   4626377  2022-02-05   9003  Cargo Shorts          Animal   38.0         1\n",
      "9   4626412  2022-02-05   9004         Shirt          Volcom   78.0         1\n",
      "10  9423783  2022-02-06   9002  Boxer Shorts        Superdry   30.0         2\n",
      "11  9423783  2022-02-06   9002        Shorts           Globe   26.0         1\n",
      "12  4626490  2022-02-06   9004  Cargo Shorts       Billabong   54.0         1\n",
      "13  4626490  2022-02-06   9004       Sweater         Dickies   56.0         1\n",
      "14  4626592         NaN      0        Shorts         Protest   48.0         1\n",
      "15  4626592         NaN      0        Shorts         Protest   48.0         1\n"
     ]
    }
   ],
   "source": [
    "df_orders_details_right = df_orders_details_right.fillna({'Empno':0}).astype({'Empno':'int64'})\n",
    "print(df_orders_details_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  author_id book_id\n",
      "0       jsn      b1\n",
      "1       jsn      b2\n",
      "2       tri      b2\n",
      "3       wsn      b3\n"
     ]
    }
   ],
   "source": [
    "# join molti a molti\n",
    "import pandas as pd\n",
    "books = pd.DataFrame({'book_id': ['b1', 'b2', 'b3'],\n",
    "                      'title': ['Beautiful Coding', 'Python for Web Development', 'Pythonic Thinking'],\n",
    "                      'topic': ['programming', 'Python, Web', 'Python']})\n",
    "authors = pd.DataFrame({'author_id': ['jsn', 'tri', 'wsn'],\n",
    "                        'author': ['Johnson', 'Treloni', 'Willson']})\n",
    "\n",
    "matching = pd.DataFrame({'author_id': ['jsn', 'jsn','tri', 'wsn'],'book_id': ['b1', 'b2', 'b2', 'b3']})\n",
    "print(matching)\n",
    "\n",
    "authorship = books.merge(matching).merge(authors)[['title','topic','author']]\n",
    "print(authorship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be93d44",
   "metadata": {},
   "source": [
    "# Esercizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa24fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9002, Jane Boorman, sales, 95\n",
      "9002, Jane Boorman, sales, 218\n"
     ]
    }
   ],
   "source": [
    "# Esercizio #8: Eseguire una join uno-a-molti\n",
    "# Modificate il codice mostrato nella sezione precedente in modo che la query sia una join\n",
    "# della tabella emps con la tabella orders. È possibile mantenere la condizione che empno sia\n",
    "# maggiore di 9001. Adattate la chiamata print() per produrre le righe della join modificata.\n",
    "\n",
    "try:  \n",
    "    cnx = mysql.connector.connect(user='root', password='PASSWORD_DI_GABRI',\n",
    "                                  host='127.0.0.1',\n",
    "                                  database='sampledb')\n",
    "    cursor = cnx.cursor()\n",
    "    query = (\"\"\"SELECT e.empno, e.empname, e.job, o.total FROM emps AS e JOIN orders AS o ON e.empno = o.empno WHERE e.empno > %s\"\"\")\n",
    "    empno = 9001\n",
    "    cursor.execute(query, (empno,))\n",
    "    for (empno, empname, job, total) in cursor:\n",
    "        print(\"{}, {}, {}, {}\".format(empno, empname, job, total))\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Error-Code:\", err.errno)\n",
    "    print(\"Error-Message: {}\".format(err.msg))\n",
    "finally:\n",
    "    cursor.close()\n",
    "    cnx.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a40f9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documenti inseriti, id: [ObjectId('68403adfaf5003d7b5d255ba'), ObjectId('68403adfaf5003d7b5d255bb'), ObjectId('68403adfaf5003d7b5d255bc')]\n",
      "Documenti trovati:\n",
      "{'_id': ObjectId('6840220baf5003d7b5d25599'), 'empno': 9001, 'empname': 'Jeff Russell', 'orders': [2608, 2617, 2620]}\n",
      "{'_id': ObjectId('684024edaf5003d7b5d255a2'), 'empno': 9002, 'empname': 'Alice Smith', 'orders': [2609, 2618]}\n",
      "{'_id': ObjectId('684024edaf5003d7b5d255a3'), 'empno': 9003, 'empname': 'Bob Johnson', 'orders': [2610]}\n",
      "{'_id': ObjectId('684024edaf5003d7b5d255a4'), 'empno': 9004, 'empname': 'Charlie Brown', 'orders': [2611, 2621, 2630]}\n",
      "{'_id': ObjectId('68403addaf5003d7b5d255b2'), 'empno': 9002, 'empname': 'Alice Smith', 'orders': [2609, 2618]}\n",
      "{'_id': ObjectId('68403addaf5003d7b5d255b3'), 'empno': 9003, 'empname': 'Bob Johnson', 'orders': [2610]}\n",
      "{'_id': ObjectId('68403addaf5003d7b5d255b4'), 'empno': 9004, 'empname': 'Charlie Brown', 'orders': [2611, 2621, 2630]}\n",
      "{'_id': ObjectId('68403adfaf5003d7b5d255b6'), 'empno': 9002, 'empname': 'Alice Smith', 'orders': [2609, 2618]}\n",
      "{'_id': ObjectId('68403adfaf5003d7b5d255b7'), 'empno': 9003, 'empname': 'Bob Johnson', 'orders': [2610]}\n",
      "{'_id': ObjectId('68403adfaf5003d7b5d255b8'), 'empno': 9004, 'empname': 'Charlie Brown', 'orders': [2611, 2621, 2630]}\n",
      "{'_id': ObjectId('68403adfaf5003d7b5d255ba'), 'empno': 9002, 'empname': 'Alice Smith', 'orders': [2609, 2618]}\n",
      "{'_id': ObjectId('68403adfaf5003d7b5d255bb'), 'empno': 9003, 'empname': 'Bob Johnson', 'orders': [2610]}\n",
      "{'_id': ObjectId('68403adfaf5003d7b5d255bc'), 'empno': 9004, 'empname': 'Charlie Brown', 'orders': [2611, 2621, 2630]}\n"
     ]
    }
   ],
   "source": [
    "# Esercizio 9: Inserire e interrogare più documenti\n",
    "# Continuando con l’insieme emps creato nel database sampledb, provate a eseguire\n",
    "# inserti massivi con il metodo insert_many() e interrogate più di un documento con il metodo find()\n",
    "\n",
    "# link insert_many(): https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.insert_many\n",
    "# link find(): https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.find\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://admin:secret@localhost:27017/\")\n",
    "db = client['sampledb'] # per accedere agli attributi: db = client.sampledb\n",
    "emps_collection = db['emps']\n",
    "# emp = {\"empno\": 9001, \"empname\": \"Jeff Russell\", \"orders\": [2608, 2617, 2620]}\n",
    "# result = emps_collection.insert_one(emp)\n",
    "\n",
    "employees = [\n",
    "    {\"empno\": 9002, \"empname\": \"Alice Smith\", \"orders\": [2609, 2618]},\n",
    "    {\"empno\": 9003, \"empname\": \"Bob Johnson\", \"orders\": [2610]},\n",
    "    {\"empno\": 9004, \"empname\": \"Charlie Brown\", \"orders\": [2611, 2621, 2630]}\n",
    "]\n",
    "result_insert = emps_collection.insert_many(employees)\n",
    "print(f\"Documenti inseriti, id: {result_insert.inserted_ids}\")\n",
    "\n",
    "# emp = emps_collection.find_one({\"empno\": 9001})\n",
    "# print(emp)\n",
    "\n",
    "print(\"Documenti trovati:\")\n",
    "for emp in emps_collection.find():\n",
    "    print(emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6131f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 documenti duplicati rimossi.\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient(\"mongodb://admin:secret@localhost:27017/\")\n",
    "db = client['sampledb']\n",
    "emps_collection = db['emps']\n",
    "# 1. Trova tutti i documenti ordinati per empno e _id (così tieni il primo inserito)\n",
    "all_docs = emps_collection.find().sort([(\"empno\", 1), (\"_id\", 1)])\n",
    "seen_empnos = set()\n",
    "to_delete_ids = []\n",
    "# 2. Identifica i duplicati\n",
    "for doc in all_docs:\n",
    "    empno = doc[\"empno\"]\n",
    "    if empno in seen_empnos:\n",
    "        to_delete_ids.append(doc[\"_id\"])\n",
    "    else:\n",
    "        seen_empnos.add(empno)\n",
    "\n",
    "# 3. Rimuovi i documenti duplicati\n",
    "if to_delete_ids:\n",
    "    result = emps_collection.delete_many({\"_id\": {\"$in\": to_delete_ids}})\n",
    "    print(f\"{result.deleted_count} documenti duplicati rimossi.\")\n",
    "else:\n",
    "    print(\"Nessun duplicato trovato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8231cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    731.0\n",
      "dtype: float64\n",
      "                 Total\n",
      "2022-02-04 East   97.0\n",
      "           West  243.0\n",
      "2022-02-05 East  160.0\n",
      "           West   35.0\n",
      "2022-02-06 East  110.0\n",
      "           West   86.0\n",
      "All        All   731.0\n",
      "         Total\n",
      "All All  731.0\n",
      "                 Total\n",
      "2022-02-04 East   97.0\n",
      "           West  243.0\n",
      "           All   340.0\n",
      "2022-02-05 East  160.0\n",
      "           West   35.0\n",
      "           All   195.0\n",
      "2022-02-06 East  110.0\n",
      "           West   86.0\n",
      "           All   196.0\n"
     ]
    }
   ],
   "source": [
    "# Esercizio 10 La presenza di righe per i totali in un DataFrame consente di utilizzarlo come report senza \n",
    "# dover aggiungere ulteriori passaggi. Tuttavia, se si intende utilizzare il DataFrame in ulteriori\n",
    "# operazioni di aggregazione, potrebbe essere necessario escludere le righe per i totali.\n",
    "#  Provate a filtrare il DataFrame df_totals creato nella sezione precedente, escludendo le \n",
    "# righe del totale generale e del subtotale. Utilizzate le tecniche di slicing discusse in questo capitolo.\n",
    "\n",
    "df_orders, df_details, df_emps, df_locations = load_data()\n",
    "df_sales = combination(df_orders, df_details, df_emps, df_locations)\n",
    "df_sales['Total'] = df_sales['Price'] * df_sales['Quantity']\n",
    "df_sales = df_sales[['Date','Empno','Total']] # Per filtrare il DataFrame fino alle colonne necessarie, occorre passare una lista dei nomi delle colonne all’operatore [] del DataFrame, come mostrato qui:\n",
    "\n",
    "df_sales_emps = df_sales.merge(df_emps)\n",
    "df_result = df_sales_emps.merge(df_locations)\n",
    "df_result = df_result[['Date','Region','Total']]\n",
    "df_date_region = df_result.groupby(['Date','Region']).sum()\n",
    "\n",
    "ps = df_date_region.sum(axis = 0)   # Aggiungere un totale generale\n",
    "print(ps)                           # sum restituisce una series pandas con la somma sulal colonna total\n",
    "ps.name=('All','All')               # il primo all si riferisce alla componente date delal chiave mentre il secondo alla Region\n",
    "\n",
    "df_date_region_total = pd.concat([df_date_region, ps.to_frame().T])\n",
    "print(df_date_region_total)\n",
    "print(df_date_region_total[df_date_region_total.index.isin([('All', 'All')])])\n",
    "\n",
    "# aggiungere totali parziali\n",
    "df_totals = []\n",
    "\n",
    "for date, date_df in df_date_region.groupby(level=0):\n",
    "    df_totals.append(date_df)  # aggiunge le righe esistenti\n",
    "    ps = date_df.sum(axis=0)\n",
    "    ps.name = (date, 'All')  # MultiIndex (data, 'All')\n",
    "    df_totals.append(ps.to_frame().T)  # aggiunge la riga di somma\n",
    "\n",
    "# Unisce tutto in un unico DataFrame\n",
    "df_totals = pd.concat(df_totals)\n",
    "print(df_totals)\n",
    "\n",
    "# SOLUZIONE in esercizio10.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59683843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esercizio 11: Aggiungere righe/colonne nuove a un array Numpy. Continuando con l’esempio precedente,\n",
    "# create un nuovo array NumPy a due colonne con le # informazioni sullo stipendio di altri due mesi per ciascun dipendente.\n",
    "# Quindi, concatenate l’array esistente base_salary con l’array appena creato. Allo stesso modo, aggiungete una\n",
    "# nuova riga all’array base_salary, aggiungendo così le informazioni sullo stipendio di un altro dipendente.\n",
    "# Notate che quando si aggiunge una singola riga o colonna a un array NumPy, è\n",
    "# possibile utilizzare la funzione numpy.append() piuttosto che numpy.concatenate().\n",
    "\n",
    "# CONCATENARE ARRAY NUMPY\n",
    "import numpy as np\n",
    "jeff_salary = [2700, 3000, 3000]\n",
    "nick_salary = [2600, 2800, 2800]\n",
    "tom_salary = [2300, 2500, 2500]\n",
    "base_salary1 = np.array([jeff_salary, nick_salary, tom_salary])\n",
    "\n",
    "maya_salary = [2200, 2400, 2400]\n",
    "john_salary = [2500, 2700, 2700]\n",
    "base_salary2 = np.array([maya_salary, john_salary])\n",
    "\n",
    "base_salary = np.concatenate((base_salary1, base_salary2), axis=0)\n",
    "print(base_salary)\n",
    "new_month_salary = np.array([[3000],[2900],[2500],[2500],[2700]])\n",
    "base_salary = np.concatenate((base_salary, new_month_salary), axis=1)\n",
    "print(base_salary)\n",
    "\n",
    "# implementato in module_07/esercizio11.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
